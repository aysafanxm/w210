{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_df(filename, valtype):\n",
    "    df = pd.read_csv(filename, low_memory=False, dtype=valtype)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict, defaultdict\n",
    "\n",
    "def create_combined_df(input_dict):\n",
    "    fdf = pd.DataFrame()\n",
    "    cols = OrderedDict()\n",
    "    for k, v in input_dict.items():\n",
    "        df = read_df('./data/'+k, v)\n",
    "        colnames = [c for c in df.columns if c not in ['None', 'Unnamed: 0']]\n",
    "        cols[k] = colnames\n",
    "        fdf = pd.concat([fdf, df], axis=1)\n",
    "    \n",
    "    # fdf = fdf.DataFrame(fdf, columns=cols)\n",
    "    fdf = fdf.drop(['None', 'Unnamed: 0'], axis=1)\n",
    "    return fdf, cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Dependent feature data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = './data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = pd.read_csv(base+'fin_train_indeps.csv', encoding='utf8')\n",
    "y_train = y_train.drop(['Unnamed: 0'], axis=1)\n",
    "y_train.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = pd.read_csv(base+'fin_test_indeps.csv', encoding='utf8')\n",
    "y_test = y_test.drop(['Unnamed: 0'], axis=1)\n",
    "y_test.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read independent feature data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = pd.read_csv(base+'fin_num_train_deps.csv')\n",
    "num_train = num_train.drop(['Unnamed: 0'], axis=1)\n",
    "num_test = pd.read_csv(base+'fin_num_test_deps.csv')\n",
    "num_test = num_test.drop(['Unnamed: 0'], axis=1)\n",
    "\n",
    "cat_train = pd.read_csv(base+'fin_cat_train_deps.csv')\n",
    "cat_train = cat_train.drop(['Unnamed: 0'], axis=1)\n",
    "cat_test = pd.read_csv(base+'fin_cat_test_deps.csv')\n",
    "cat_test = cat_test.drop(['Unnamed: 0'], axis=1)\n",
    "\n",
    "amen_train = pd.read_csv(base+'fin_amen_train_deps.csv')\n",
    "amen_train = amen_train.drop(['Unnamed: 0'], axis=1)\n",
    "amen_test = pd.read_csv(base+'fin_amen_test_deps.csv')\n",
    "amen_test = amen_test.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_train = pd.read_csv(base+'fin_comb_train_deps.csv')\n",
    "comb_train = comb_train.drop(['Unnamed: 0'], axis=1)\n",
    "comb_test = pd.read_csv(base+'fin_comb_test_deps.csv')\n",
    "comb_test = comb_test.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Test data into Holdout and Validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1234)\n",
    "idxs = np.random.randint(0, y_test.shape[0], y_test.shape[0]//2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_validation = y_test.iloc[~y_test.index.isin(idxs)]\n",
    "y_holdout = y_test.iloc[idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_validation = num_test.iloc[~num_test.index.isin(idxs)]\n",
    "num_holdout = num_test.iloc[idxs]\n",
    "\n",
    "cat_validation = cat_test.iloc[~cat_test.index.isin(idxs)]\n",
    "cat_holdout = cat_test.iloc[idxs]\n",
    "\n",
    "amen_validation = amen_test.iloc[~amen_test.index.isin(idxs)]\n",
    "amen_holdout = amen_test.iloc[idxs]\n",
    "\n",
    "comb_validation = comb_test.iloc[~comb_test.index.isin(idxs)]\n",
    "comb_holdout = comb_test.iloc[idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(X, y, Xt, yt, model):\n",
    "    if len(y.shape) == 1:\n",
    "        y = y.reshape(-1, 1)\n",
    "    if len(yt.shape) == 1:\n",
    "        yt = yt.reshape(-1, 1)\n",
    "    \n",
    "    res = {'train': {}, 'test': {}}\n",
    "    \n",
    "    model.fit(X, y)\n",
    "    \n",
    "    train_pred = model.predict(X)\n",
    "    res['train']['pred'] = train_pred\n",
    "    \n",
    "    test_pred = model.predict(Xt)\n",
    "    res['test']['pred'] = test_pred\n",
    "    \n",
    "    for name, tup in zip(['train', 'test'], [(y, train_pred), (yt, test_pred)]):\n",
    "        act = tup[0].values \n",
    "        prd = tup[1].ravel()\n",
    "        \n",
    "        mserr = mean_squared_error(act, prd)\n",
    "        res[name]['mse'] = mserr\n",
    "        \n",
    "        rsq_score = r2_score(act, prd)\n",
    "        res[name]['r2'] = rsq_score\n",
    "    \n",
    "    return model, res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model_resgen(X, y, Xt, yt, model, sample_sizes=[]):\n",
    "    for ss in sample_sizes:\n",
    "        np.random.seed(1234)\n",
    "        rand_idxs = np.random.randint(0, X.shape[0], size=ss)\n",
    "        Xs = X.iloc[rand_idxs]\n",
    "        ys = y.iloc[rand_idxs]\n",
    "        \n",
    "        yield run_model(Xs, ys, Xt, yt, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "sample_sizes = [i for i in range(1000, num_train.shape[0], 2500)] + [num_train.shape[0]]\n",
    "\n",
    "regr = linear_model.Lasso(alpha=0.01, fit_intercept=True, max_iter=10000)\n",
    "\n",
    "\n",
    "def plot_model_results(X, y, Xt, yt, model, sample_sizes):\n",
    "    mse_train = []\n",
    "    mse_test = []\n",
    "    r2_train = []\n",
    "    r2_test = []\n",
    "\n",
    "    for _, r in run_model_resgen(X, y, Xt, yt, model, sample_sizes):\n",
    "        mse_train.append(r['train']['mse'])\n",
    "        mse_test.append(r['test']['mse'])        \n",
    "        r2_train.append(r['train']['r2'])\n",
    "        r2_test.append(r['test']['r2'])        \n",
    "    \n",
    "    \n",
    "    \n",
    "    fig = plt.figure(figsize=(10, 7))\n",
    "    ax1 = fig.add_subplot(111)\n",
    "    alph = 0.75\n",
    "    ln1 = ax1.plot(sample_sizes, mse_train, 'b-', color='b', alpha=alph, label='Train MSE')\n",
    "    ln2 = ax1.plot(sample_sizes, mse_test, 'b--', color='b', alpha=alph, label='Test MSE')\n",
    "    ax1.set_xlabel('sample size')\n",
    "    ax1.set_ylabel('MSE', color='b')\n",
    "    ax1.tick_params('y', colors='b')\n",
    "\n",
    "    ax2 = ax1.twinx()\n",
    "    ln3 = ax2.plot(sample_sizes, r2_train, 'g-', color='g', alpha=alph, label='Train R2')\n",
    "    ln4 = ax2.plot(sample_sizes, r2_test, 'g--', color='g', alpha=alph, label='Test R2')\n",
    "    ax2.set_ylabel('R2', color='g')\n",
    "    ax2.tick_params('y', colors='g')\n",
    "    \n",
    "    lns = ln1 + ln2 + ln3 + ln4\n",
    "    labs = [l.get_label() for l in lns]\n",
    "    ax1.legend(lns, labs)\n",
    "    \n",
    "    # fig.tight_layout()\n",
    "    # plt.legend()\n",
    "    plt.title('Train and Test MSE and R2 vs. sample size') \n",
    "    plt.show()\n",
    "    \n",
    "    model = _ # Just the final model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = plot_model_results(num_train, y_train, num_validation, y_validation, regr, sample_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = plot_model_results(cat_train, y_train, cat_validation, y_validation, regr, sample_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = plot_model_results(amen_train, y_train, amen_validation, y_validation, regr, sample_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = plot_model_results(comb_train, y_train, comb_validation, y_validation, regr, sample_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vecstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "from vecstack import StackingTransformer\n",
    "from vecstack import stacking\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge, ElasticNet, Lasso\n",
    "from sklearn.ensemble import AdaBoostRegressor, GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "def rmse(train, pred):\n",
    "    return mean_squared_error(train, pred)\n",
    "\n",
    "\n",
    "def rsq(train, pred):\n",
    "    return r2_score(train, pred)\n",
    "\n",
    "lass = Lasso(alpha=0.001, fit_intercept=False, max_iter=10000)\n",
    "\n",
    "ridge = Ridge(normalize=False, alpha=0.1, max_iter=10000)\n",
    "\n",
    "gb = GradientBoostingRegressor(n_estimators=100, learning_rate=0.01, \n",
    "                               subsample=0.75, max_depth=15)\n",
    "\n",
    "xgb = xgboost.XGBRegressor(n_estimators=100, learning_rate=0.05, \n",
    "                           gamma=0, subsample=0.5, colsample_bytree=0.5, \n",
    "                           max_depth=15, objective='reg:linear')\n",
    "\n",
    "randf = RandomForestRegressor(n_estimators=100, min_samples_split=10)\n",
    "\n",
    "svr_rbf = SVR(kernel='rbf')\n",
    "\n",
    "\n",
    "estimators = [\n",
    "              ('ridge', ridge),\n",
    "              ('gbf', GradientBoostingRegressor(alpha=0.001)), \n",
    "              ('randf', randf), \n",
    "             ]\n",
    "\n",
    "stack = StackingTransformer(estimators, regression=True, \n",
    "                            shuffle=True, n_folds=10, \n",
    "                            metric=rmse, verbose=2, \n",
    "                           )\n",
    "\n",
    "stack = stack.fit(comb_train, y_train)\n",
    "\n",
    "# Get stacked features\n",
    "S_train = stack.transform(comb_train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_test = stack.transform(comb_validation)\n",
    "\n",
    "# Use 2nd level estimator on Stacked data\n",
    "# model = RandomForestRegressor(n_estimators=100, min_impurity_decrease=0.05)\n",
    "model = xgb\n",
    "\n",
    "model.fit(S_train, y_train)\n",
    "\n",
    "y_train_pred = model.predict(S_train)\n",
    "\n",
    "# Make predictions using the testing set\n",
    "y_pred = model.predict(S_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The mean squared error\n",
    "print(\"Train Mean squared error: %.2f\"\n",
    "      % mean_squared_error(y_train, y_train_pred))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print 'Train Variance score: %.2f' % r2_score(y_train, y_train_pred) \n",
    "\n",
    "# The mean squared error\n",
    "print(\"Validation Mean squared error: %.2f\"\n",
    "      % mean_squared_error(y_validation, y_pred))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print 'Validation Variance score: %.2f' % r2_score(y_validation, y_pred) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_test = stack.transform(comb_validation)\n",
    "\n",
    "# Use 2nd level estimator on Stacked data\n",
    "# model = RandomForestRegressor(n_estimators=100, min_impurity_decrease=0.05)\n",
    "model = gb\n",
    "\n",
    "model.fit(S_train, y_train)\n",
    "\n",
    "y_train_pred = model.predict(S_train)\n",
    "\n",
    "# Make predictions using the testing set\n",
    "y_pred = model.predict(S_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The mean squared error\n",
    "print(\"Train Mean squared error: %.2f\"\n",
    "      % mean_squared_error(y_train, y_train_pred))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print 'Train Variance score: %.2f' % r2_score(y_train, y_train_pred) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The mean squared error\n",
    "print(\"Validation Mean squared error: %.2f\"\n",
    "      % mean_squared_error(y_validation, y_pred))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print 'Validation Variance score: %.2f' % r2_score(y_validation, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "print y_holdout.shape\n",
    "print y_validation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.subtract(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the residuals\n",
    "print 'train residuals:'\n",
    "plt.scatter(y_train.values, , c='b', marker='o', alpha=0.5)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrap_vec_stack(X, y, Xt, yt, sample_sizes, sstack, mmodel):\n",
    "\n",
    "    for ss in sample_sizes:\n",
    "        np.random.seed(1234)\n",
    "        rand_idxs = np.random.randint(0, X.shape[0], size=ss)\n",
    "        Xs = X.iloc[rand_idxs]\n",
    "        ys = y.iloc[rand_idxs]\n",
    "\n",
    "        stack = sstack.fit(Xs, ys)\n",
    "        \n",
    "        # Get stacked features\n",
    "        S_train = stack.transform(Xs)\n",
    "        S_test = stack.transform(Xt)\n",
    "\n",
    "        # Use 2nd level estimator on Stacked data\n",
    "        # model = RandomForestRegressor(n_estimators=100, min_impurity_decrease=0.05)\n",
    "        model = mmodel\n",
    "        plot_model_results(Xs, ys, Xt, yt, model, [ss])\n",
    "\n",
    "\n",
    "# wrap_vec_stack(comb_train, y_train, comb_validation, y_validation, sample_sizes, stack, xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, make_scorer, roc_auc_score\n",
    "\n",
    "m_train = np.mean(y_train)\n",
    "y_train_baseline_pred = np.array([m_train for i in range(y_train.shape[0])])\n",
    "y_validation_baseline_pred = np.array([m_train for i in range(y_validation.shape[0])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print y_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "print y_train.shape\n",
    "print y_train_baseline_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The mean squared error\n",
    "print(\"Train Mean squared error: %.2f\"\n",
    "      % mean_squared_error(y_train, y_train_baseline_pred))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Train Validation Variance score: %.2f' % r2_score(y_train, y_train_baseline_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# The mean squared error\n",
    "print(\"Validation Mean squared error: %.2f\"\n",
    "      % mean_squared_error(y_validation, y_validation_baseline_pred))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Validation Variance score: %.2f' % r2_score(y_validation, y_validation_baseline_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Objective: Implement a wrapper for vecstack\n",
    "# InputL scikit model instances and training data\n",
    "# Output: Predictions\n",
    "\n",
    "import vecstack\n",
    "import dill\n",
    "\n",
    "import xgboost\n",
    "import dill as pickle\n",
    "from copy import deepcopy \n",
    "from vecstack import StackingTransformer\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "class VecstackRunner():\n",
    "\n",
    "    def __init__(self, X, y, Xt, yt, l1_estimators, l2_estimator, prfx='', metric='rmse', regression=True, nfolds=10, verbose=2):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.Xt = Xt\n",
    "        self.yt = yt\n",
    "        self.yp = None\n",
    "        self.ytp = None\n",
    "        self.l1 = l1_estimators\n",
    "        self.l2 = l2_estimator\n",
    "        self.prfx = prfx\n",
    "        self.metname = metric\n",
    "        self.nf = nfolds\n",
    "        self.v = verbose\n",
    "        self.is_reg = regression\n",
    "        self.stack = None\n",
    "    \n",
    "    def mse(self, actual, pred):\n",
    "        return mean_squared_error(actual, pred)\n",
    "    \n",
    "    def rsq(self, actual, pred):\n",
    "        return r2_score(actual, pred)\n",
    "    \n",
    "    def get_metric_calc(self, actual, pred):\n",
    "        if 'rmse' == self.metname:\n",
    "            return self.mse(actual, pred)\n",
    "        elif 'r2' == self.metname:\n",
    "            return self.rsq(actual, pred)\n",
    "    \n",
    "    def build_stack(self):\n",
    "        self.stack = StackingTransformer(self.l1, \n",
    "                                        regression=self.is_reg, \n",
    "                                        shuffle=True, \n",
    "                                        n_folds=self.nf, \n",
    "                                        metric=self.get_metric_calc, \n",
    "                                        verbose=self.v)\n",
    "    \n",
    "    def fit_stack(self):\n",
    "        return self.stack.fit(self.X, self.y)\n",
    "    \n",
    "    def transform(self):\n",
    "        self.X = self.stack.transform(self.X)\n",
    "        self.Xt = self.stack.transform(self.Xt)\n",
    "    \n",
    "    def fit_l2(self):\n",
    "        self.l2.fit(self.X, self.y)\n",
    "    \n",
    "    def predict(self):\n",
    "        self.yp = self.l2.predict(self.X)\n",
    "        self.ytp = self.l2.predict(self.Xt)\n",
    "    \n",
    "    def calculate_error(self, calc=None):\n",
    "        if calc:\n",
    "            y_err = calc(self.y, self.yp)\n",
    "            yp_err = calc(self.y, self.ytp)\n",
    "        else:\n",
    "            y_err = self.get_metric_calc(self.y, self.yp)\n",
    "            yt_err = self.get_metric_calc(self.yt, self.ytp)\n",
    "            \n",
    "        return [('Train err', y_err), ('Test err', yt_err)]\n",
    "    \n",
    "    def save_to_disk(self):\n",
    "        sname = self.prfx+'_vecstack_stack.pkl'\n",
    "        cname = self.prfx+'_vecstack_clf.pkl'\n",
    "        \n",
    "        with open('./data/'+sname, 'wb') as f:\n",
    "            pickle.dump(self.stack,f)\n",
    "        \n",
    "        with open('./data/'+cname, 'wb') as f:\n",
    "            pickle.dump(self.l2, f)\n",
    "    \n",
    "    def run(self):\n",
    "        self.build_stack()\n",
    "        self.fit_stack()\n",
    "        self.transform()\n",
    "        self.fit_l2()\n",
    "        self.predict()\n",
    "        self.save_to_disk()\n",
    "        return self.calculate_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet, Lasso, Ridge\n",
    "from sklearn.ensemble import AdaBoostRegressor, GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "\n",
    "en = ElasticNet(alpha=0.001)\n",
    "lass = Lasso(alpha=0.001, fit_intercept=False, max_iter=10000)\n",
    "ridge = Ridge(normalize=False, alpha=0.1, max_iter=10000)\n",
    "gb = GradientBoostingRegressor(n_estimators=100, learning_rate=0.01, \n",
    "                               subsample=0.75, max_depth=15)\n",
    "ab = AdaBoostRegressor(n_estimators=100, learning_rate=0.01)\n",
    "xgb = xgboost.XGBRegressor(n_estimators=100, learning_rate=0.05, \n",
    "                           gamma=0, subsample=0.5, \n",
    "                           max_depth=15, objective='reg:linear')\n",
    "randf = RandomForestRegressor(n_estimators=100, min_samples_split=10)\n",
    "svr_rbf = SVR(kernel='rbf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [\n",
    "                ('en', en), \n",
    "                ('lass', lass), \n",
    "                ('ridge', ridge),\n",
    "                ('gb', gb), \n",
    "                ('ab', ab), \n",
    "                ('randf', randf), \n",
    "             ]\n",
    "\n",
    "base = './data/'\n",
    "prf = 'num'\n",
    "vr = VecstackRunner(num_train, y_train, num_test, y_test, l1_estimators=estimators, l2_estimator=xgb, prfx=prf)\n",
    "vr.run()\n",
    "\n",
    "with open(base+prf+'_vecstack_stack.pkl', 'rb') as f:\n",
    "    ts = pickle.load(f)\n",
    "\n",
    "with open(base+prf+'_vecstack_clf.pkl', 'rb') as f:\n",
    "    tc = pickle.load(f)\n",
    "    \n",
    "print mean_squared_error(y_test, tc.predict(ts.transform(num_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [\n",
    "                ('en', en), \n",
    "                ('lass', lass), \n",
    "                ('ridge', ridge),\n",
    "                ('gb', gb), \n",
    "                ('ab', ab), \n",
    "                ('randf', randf), \n",
    "             ]\n",
    "\n",
    "base = '/tmp/'\n",
    "prf = 'cat'\n",
    "vr = VecstackRunner(cat_train, y_train, cat_test, y_test, estimators, xgb, prfx=prf)\n",
    "vr.run()\n",
    "\n",
    "with open(base+prf+'_vecstack_stack.pkl', 'rb') as f:\n",
    "    ts = pickle.load(f)\n",
    "\n",
    "with open(base+prf+'_vecstack_clf.pkl', 'rb') as f:\n",
    "    tc = pickle.load(f)\n",
    "\n",
    "print mean_squared_error(y_test, tc.predict(ts.transform(cat_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [\n",
    "                ('en', en), \n",
    "                ('lass', lass), \n",
    "                ('ridge', ridge),\n",
    "                ('gb', gb), \n",
    "                ('ab', ab), \n",
    "                ('randf', randf), \n",
    "             ]\n",
    "\n",
    "base = '/tmp/'\n",
    "prf = 'amen'\n",
    "vr = VecstackRunner(amen_train, y_train, amen_test, y_test, estimators, xgb, prfx=prf)\n",
    "vr.run()\n",
    "\n",
    "with open(base+prf+'_vecstack_stack.pkl', 'rb') as f:\n",
    "    ts = pickle.load(f)\n",
    "\n",
    "with open(base+prf+'_vecstack_clf.pkl', 'rb') as f:\n",
    "    tc = pickle.load(f)\n",
    "\n",
    "print mean_squared_error(y_test, tc.predict(ts.transform(amen_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [\n",
    "                ('en', en), \n",
    "                ('lass', lass), \n",
    "                ('ridge', ridge),\n",
    "                ('gb', gb), \n",
    "                ('ab', ab), \n",
    "                ('randf', randf), \n",
    "             ]\n",
    "https://github.com/jansonclui/w210_capstone_project/raw/master/tfidf_sentiment.csv\n",
    "base = '/tmp/'\n",
    "prf = 'comb'\n",
    "vr = VecstackRunner(comb_train, y_train, comb_validation, y_validation, estimators, xgb, prfx=prf)\n",
    "vr.run()\n",
    "\n",
    "with open(base+prf+'_vecstack_stack.pkl', 'rb') as f:\n",
    "    ts = pickle.load(f)\n",
    "\n",
    "with open(base+prf+'_vecstack_clf.pkl', 'rb') as f:\n",
    "    tc = pickle.load(f)\n",
    "\n",
    "print mean_squared_error(y_validation, tc.predict(ts.transform(comb_validation)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions to use model predictions as meta features\n",
    "\n",
    "def get_meta_features(X, y, Xt, model):\n",
    "    model.fit(X, y)\n",
    "    return { 'train': model.predict(X), 'test': model.predict(Xt) }\n",
    "\n",
    "def build_meta_features(X, y, Xt, estimators):\n",
    "\n",
    "    train_meta = pd.DataFrame()\n",
    "    test_meta = pd.DataFrame()\n",
    "    \n",
    "    models = [e[1] for e in estimators]\n",
    "    \n",
    "    for model in models:\n",
    "        r = get_meta_features(X, y, Xt)\n",
    "        train_meta = pd.concat([train_meta, r['train'].ravel()], axis=1)\n",
    "        test_meta = pd.concat([test_meta, r['test'].ravel()], axis=1)\n",
    "        \n",
    "    return {'train': train_meta, 'test': test_meta}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
