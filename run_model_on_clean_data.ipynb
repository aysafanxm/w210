{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine Numeric and Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_df(filename, valtype):\n",
    "    df = pd.read_csv(filename, low_memory=False, dtype=valtype)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict, defaultdict\n",
    "\n",
    "def create_combined_df(input_dict):\n",
    "    fdf = pd.DataFrame()\n",
    "    cols = OrderedDict()\n",
    "    for k, v in input_dict.items():\n",
    "        df = read_df('./data/'+k, v)\n",
    "        colnames = [c for c in df.columns if c not in ['None', 'Unnamed: 0']]\n",
    "        cols[k] = colnames\n",
    "        fdf = pd.concat([fdf, df], axis=1)\n",
    "    \n",
    "    # fdf = fdf.DataFrame(fdf, columns=cols)\n",
    "    fdf = fdf.drop(['None', 'Unnamed: 0'], axis=1)\n",
    "    return fdf, cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Dependent feature data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_scores_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>62932</th>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       review_scores_rating\n",
       "62932                 100.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = pd.read_csv('./data/fin_train_indeps.csv', encoding='utf8')\n",
    "y_train = y_train.drop(['Unnamed: 0'], axis=1)\n",
    "y_train.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 80.,  81.,  82.,  83.,  84.,  85.,  86.,  87.,  88.,  89.,  90.,\n",
       "        91.,  92.,  93.,  94.,  95.,  96.,  97.,  98.,  99., 100.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_scores_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>98.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     review_scores_rating\n",
       "433                  98.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = pd.read_csv('./data/fin_test_indeps.csv', encoding='utf8')\n",
    "y_test = y_test.drop(['Unnamed: 0'], axis=1)\n",
    "y_test.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 80.,  81.,  82.,  83.,  84.,  85.,  86.,  87.,  88.,  89.,  90.,\n",
       "        91.,  92.,  93.,  94.,  95.,  96.,  97.,  98.,  99., 100.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read independent feature data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = pd.read_csv('./data/fin_num_train_deps.csv')\n",
    "num_train = num_train.drop(['Unnamed: 0'], axis=1)\n",
    "num_test = pd.read_csv('./data/fin_num_test_deps.csv')\n",
    "num_test = num_test.drop(['Unnamed: 0'], axis=1)\n",
    "\n",
    "cat_train = pd.read_csv('./data/fin_cat_train_deps.csv')\n",
    "cat_train = cat_train.drop(['Unnamed: 0'], axis=1)\n",
    "cat_test = pd.read_csv('./data/fin_cat_test_deps.csv')\n",
    "cat_test = cat_test.drop(['Unnamed: 0'], axis=1)\n",
    "\n",
    "amen_train = pd.read_csv('./data/fin_amen_train_deps.csv')\n",
    "amen_train = amen_train.drop(['Unnamed: 0'], axis=1)\n",
    "amen_test = pd.read_csv('./data/fin_amen_test_deps.csv')\n",
    "amen_test = amen_test.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_train = pd.read_csv('./data/fin_comb_train_deps.csv')\n",
    "comb_train = comb_train.drop(['Unnamed: 0'], axis=1)\n",
    "comb_test = pd.read_csv('./data/fin_comb_test_deps.csv')\n",
    "comb_test = comb_test.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Test data into Holdout and Validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1234)\n",
    "idxs = np.random.randint(0, y_test.shape[0], y_test.shape[0]//2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_validation = y_test.iloc[~y_test.index.isin(idxs)]\n",
    "y_holdout = y_test.iloc[idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_validation = num_test.iloc[~num_test.index.isin(idxs)]\n",
    "num_holdout = num_test.iloc[idxs]\n",
    "\n",
    "cat_validation = cat_test.iloc[~cat_test.index.isin(idxs)]\n",
    "cat_holdout = cat_test.iloc[idxs]\n",
    "\n",
    "amen_validation = amen_test.iloc[~amen_test.index.isin(idxs)]\n",
    "amen_holdout = amen_test.iloc[idxs]\n",
    "\n",
    "comb_validation = comb_test.iloc[~comb_test.index.isin(idxs)]\n",
    "comb_holdout = comb_test.iloc[idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(X, y, Xt, yt, model):\n",
    "    if len(y.shape) == 1:\n",
    "        y = y.reshape(-1, 1)\n",
    "    if len(yt.shape) == 1:\n",
    "        yt = yt.reshape(-1, 1)\n",
    "    \n",
    "    res = {'train': {}, 'test': {}}\n",
    "    \n",
    "    model.fit(X, y)\n",
    "    \n",
    "    train_pred = model.predict(X)\n",
    "    res['train']['pred'] = train_pred\n",
    "    \n",
    "    test_pred = model.predict(Xt)\n",
    "    res['test']['pred'] = test_pred\n",
    "    \n",
    "    for name, tup in zip(['train', 'test'], [(y, train_pred), (yt, test_pred)]):\n",
    "        act = tup[0].values \n",
    "        prd = tup[1].ravel()\n",
    "        \n",
    "        mserr = mean_squared_error(act, prd)\n",
    "        res[name]['mse'] = mserr\n",
    "        \n",
    "        rsq_score = r2_score(act, prd)\n",
    "        res[name]['r2'] = rsq_score\n",
    "    \n",
    "    return model, res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model_resgen(X, y, Xt, yt, model, sample_sizes=[]):\n",
    "    for ss in sample_sizes:\n",
    "        np.random.seed(1234)\n",
    "        rand_idxs = np.random.randint(0, X.shape[0], size=ss)\n",
    "        Xs = X.iloc[rand_idxs]\n",
    "        ys = y.iloc[rand_idxs]\n",
    "        \n",
    "        yield run_model(Xs, ys, Xt, yt, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "sample_sizes = [i for i in range(1000, num_train.shape[0] // 10, 2500)] # + [num_train.shape[0]]\n",
    "\n",
    "regr = linear_model.Lasso(alpha=0.001, fit_intercept=True, max_iter=10000)\n",
    "\n",
    "\n",
    "def plot_model_results(X, y, Xt, yt, model, sample_sizes):\n",
    "    mse_train = []\n",
    "    mse_test = []\n",
    "    r2_train = []\n",
    "    r2_test = []\n",
    "\n",
    "    for _, r in run_model_resgen(X, y, Xt, yt, model, sample_sizes):\n",
    "        mse_train.append(r['train']['mse'])\n",
    "        mse_test.append(r['test']['mse'])        \n",
    "        r2_train.append(r['train']['r2'])\n",
    "        r2_test.append(r['test']['r2'])        \n",
    "    \n",
    "    \n",
    "    \n",
    "    fig = plt.figure(figsize=(10, 7))\n",
    "    ax1 = fig.add_subplot(111)\n",
    "    alph = 0.75\n",
    "    ln1 = ax1.plot(sample_sizes, mse_train, 'b-', color='b', alpha=alph, label='Train MSE')\n",
    "    ln2 = ax1.plot(sample_sizes, mse_test, 'b--', color='b', alpha=alph, label='Test MSE')\n",
    "    ax1.set_xlabel('sample size')\n",
    "    ax1.set_ylabel('MSE', color='b')\n",
    "    ax1.tick_params('y', colors='b')\n",
    "\n",
    "    ax2 = ax1.twinx()\n",
    "    ln3 = ax2.plot(sample_sizes, r2_train, 'g-', color='g', alpha=alph, label='Train R2')\n",
    "    ln4 = ax2.plot(sample_sizes, r2_test, 'g--', color='g', alpha=alph, label='Test R2')\n",
    "    ax2.set_ylabel('R2', color='g')\n",
    "    ax2.tick_params('y', colors='g')\n",
    "    \n",
    "    lns = ln1 + ln2 + ln3 + ln4\n",
    "    labs = [l.get_label() for l in lns]\n",
    "    ax1.legend(lns, labs)\n",
    "    \n",
    "    # fig.tight_layout()\n",
    "    # plt.legend()\n",
    "    plt.title('Train and Test MSE and R2 vs. sample size') \n",
    "    plt.show()\n",
    "    \n",
    "    model = _ # Just the final model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model = plot_model_results(num_train, y_train, num_validation, y_validation, regr, sample_sizes)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model = plot_model_results(cat_train, y_train, cat_validation, y_validation, regr, sample_sizes)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model = plot_model_results(amen_train, y_train, amen_validation, y_validation, regr, sample_sizes)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "model = plot_model_results(comb_train, y_train, comb_validation, y_validation, regr, sample_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jhabib/miniconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task:         [regression]\n",
      "metric:       [rmse]\n",
      "variant:      [A]\n",
      "n_estimators: [2]\n",
      "\n",
      "estimator  0: [gbf: GradientBoostingRegressor]\n",
      "    fold  0:  [21.23945467]\n",
      "    fold  1:  [20.76586612]\n",
      "    fold  2:  [21.17541615]\n",
      "    fold  3:  [20.75589301]\n",
      "    fold  4:  [21.29169119]\n",
      "    fold  5:  [21.07909745]\n",
      "    fold  6:  [20.66629099]\n",
      "    fold  7:  [21.37865229]\n",
      "    fold  8:  [21.20093126]\n",
      "    fold  9:  [20.63771908]\n",
      "    ----\n",
      "    MEAN:     [21.01910122] + [0.26768787]\n",
      "\n",
      "estimator  1: [randf: RandomForestRegressor]\n",
      "    fold  0:  [6.71063206]\n",
      "    fold  1:  [6.00937631]\n",
      "    fold  2:  [6.17470635]\n",
      "    fold  3:  [6.45418212]\n",
      "    fold  4:  [6.51273145]\n",
      "    fold  5:  [6.30682018]\n",
      "    fold  6:  [6.06605726]\n",
      "    fold  7:  [7.04123697]\n",
      "    fold  8:  [6.45738348]\n",
      "    fold  9:  [6.27281665]\n",
      "    ----\n",
      "    MEAN:     [6.40059428] + [0.29433493]\n",
      "\n",
      "Train set was detected.\n",
      "Transforming...\n",
      "\n",
      "estimator  0: [gbf: GradientBoostingRegressor]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    model from fold  5: done\n",
      "    model from fold  6: done\n",
      "    model from fold  7: done\n",
      "    model from fold  8: done\n",
      "    model from fold  9: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  1: [randf: RandomForestRegressor]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    model from fold  5: done\n",
      "    model from fold  6: done\n",
      "    model from fold  7: done\n",
      "    model from fold  8: done\n",
      "    model from fold  9: done\n",
      "    ----\n",
      "    DONE\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xgboost\n",
    "from vecstack import StackingTransformer\n",
    "from vecstack import stacking\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge, ElasticNet, Lasso\n",
    "from sklearn.ensemble import AdaBoostRegressor, GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "def rmse(train, pred):\n",
    "    return mean_squared_error(train, pred)\n",
    "\n",
    "\n",
    "def rsq(train, pred):\n",
    "    return r2_score(train, pred)\n",
    "\n",
    "lass = Lasso(alpha=0.001, fit_intercept=False, max_iter=1000)\n",
    "\n",
    "ridge = Ridge(normalize=False, alpha=0.001, max_iter=1000)\n",
    "\n",
    "gb = GradientBoostingRegressor(n_estimators=100, learning_rate=0.01, \n",
    "                               subsample=0.75, max_depth=15)\n",
    "\n",
    "xgb = xgboost.XGBRegressor(n_estimators=100, learning_rate=0.05, \n",
    "                           gamma=0, subsample=0.5, colsample_bytree=0.5, \n",
    "                           max_depth=15, objective='reg:linear')\n",
    "\n",
    "randf = RandomForestRegressor(n_estimators=100, min_samples_split=10)\n",
    "\n",
    "svr_rbf = SVR(kernel='rbf')\n",
    "\n",
    "\n",
    "estimators = [\n",
    "              ('gbf', GradientBoostingRegressor(alpha=0.001)), \n",
    "              ('randf', randf), \n",
    "             ]\n",
    "\n",
    "stack = StackingTransformer(estimators, regression=True, \n",
    "                            shuffle=True, n_folds=10, \n",
    "                            metric=rmse, verbose=2, \n",
    "                           )\n",
    "\n",
    "stack = stack.fit(comb_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming...\n",
      "\n",
      "estimator  0: [gbf: GradientBoostingRegressor]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    model from fold  5: done\n",
      "    model from fold  6: done\n",
      "    model from fold  7: done\n",
      "    model from fold  8: done\n",
      "    model from fold  9: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  1: [randf: RandomForestRegressor]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    model from fold  5: done\n",
      "    model from fold  6: done\n",
      "    model from fold  7: done\n",
      "    model from fold  8: done\n",
      "    model from fold  9: done\n",
      "    ----\n",
      "    DONE\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get stacked features\n",
    "S_train = stack.transform(comb_train)\n",
    "S_test = stack.transform(comb_validation)\n",
    "\n",
    "# Use 2nd level estimator on Stacked data\n",
    "# model = RandomForestRegressor(n_estimators=100, min_impurity_decrease=0.05)\n",
    "model = xgb\n",
    "\n",
    "model.fit(S_train, y_train)\n",
    "\n",
    "y_train_pred = model.predict(S_train)\n",
    "\n",
    "# Make predictions using the testing set\n",
    "y_pred = model.predict(S_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Mean squared error: 5.40\n",
      "Train Variance score: 0.79\n"
     ]
    }
   ],
   "source": [
    "# The mean squared error\n",
    "print(\"Train Mean squared error: %.2f\"\n",
    "      % mean_squared_error(y_train, y_train_pred))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print 'Train Variance score: %.2f' % r2_score(y_train, y_train_pred) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Mean squared error: 6.27\n",
      "Validation Variance score: 0.75\n"
     ]
    }
   ],
   "source": [
    "# The mean squared error\n",
    "print(\"Validation Mean squared error: %.2f\"\n",
    "      % mean_squared_error(y_validation, y_pred))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print 'Validation Variance score: %.2f' % r2_score(y_validation, y_pred) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-854958874cc2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'y_train' is not defined"
     ]
    }
   ],
   "source": [
    "print type(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.subtract(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train residuals:\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "x and y must be the same size",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-349cb65546ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Plot the residuals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m'train residuals:'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'b'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'o'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jhabib/miniconda2/lib/python2.7/site-packages/matplotlib/pyplot.pyc\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, hold, data, **kwargs)\u001b[0m\n\u001b[1;32m   3468\u001b[0m                          \u001b[0mvmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3469\u001b[0m                          \u001b[0mlinewidths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlinewidths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3470\u001b[0;31m                          edgecolors=edgecolors, data=data, **kwargs)\n\u001b[0m\u001b[1;32m   3471\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3472\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwashold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jhabib/miniconda2/lib/python2.7/site-packages/matplotlib/__init__.pyc\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1853\u001b[0m                         \u001b[0;34m\"the Matplotlib list!)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1854\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1855\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1856\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1857\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
      "\u001b[0;32m/Users/jhabib/miniconda2/lib/python2.7/site-packages/matplotlib/axes/_axes.pyc\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, **kwargs)\u001b[0m\n\u001b[1;32m   4241\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4242\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4243\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"x and y must be the same size\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4245\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must be the same size"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the residuals\n",
    "print 'train residuals:'\n",
    "plt.scatter(y_train.values, , c='b', marker='o', alpha=0.5)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrap_vec_stack(X, y, Xt, yt, sample_sizes, sstack, mmodel):\n",
    "\n",
    "    for ss in sample_sizes:\n",
    "        np.random.seed(1234)\n",
    "        rand_idxs = np.random.randint(0, X.shape[0], size=ss)\n",
    "        Xs = X.iloc[rand_idxs]\n",
    "        ys = y.iloc[rand_idxs]\n",
    "\n",
    "        stack = sstack.fit(Xs, ys)\n",
    "        \n",
    "        # Get stacked features\n",
    "        S_train = stack.transform(Xs)\n",
    "        S_test = stack.transform(Xt)\n",
    "\n",
    "        # Use 2nd level estimator on Stacked data\n",
    "        # model = RandomForestRegressor(n_estimators=100, min_impurity_decrease=0.05)\n",
    "        model = mmodel\n",
    "        plot_model_results(Xs, ys, Xt, yt, model, [ss])\n",
    "\n",
    "\n",
    "# wrap_vec_stack(comb_train, y_train, comb_validation, y_validation, sample_sizes, stack, xgb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
